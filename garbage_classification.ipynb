{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuutQ4m08l3B",
        "outputId": "08c8581f-b3a5-40c7-816c-64d5dc59b44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'garbage_classification_week1'...\n",
            "remote: Enumerating objects: 2613, done.\u001b[K\n",
            "remote: Counting objects: 100% (2613/2613), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2606/2606), done.\u001b[K\n",
            "remote: Total 2613 (delta 54), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (2613/2613), 21.18 MiB | 24.53 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Apoorva5036/garbage_classification_week1.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_path = '/content/garbage_classification_week1/dataset'\n",
        "print(\"Classes:\", os.listdir(data_path))  # should list class folders like 'glass', 'metal', etc.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehPgGoDZFHF-",
        "outputId": "26a85c44-e02d-4c93-b5c4-000dd5d90893"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['glass', 'trash', 'metal', 'plastic', 'cardboard', 'paper']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset path (update if needed)\n",
        "dataset_path = \"/content/garbage_classification_week1/dataset\"\n",
        "\n",
        "# Image settings\n",
        "image_size = (260, 260)\n",
        "batch_size = 32\n",
        "\n",
        "# Load training dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load validation dataset\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Prefetch for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNCri341Fbe9",
        "outputId": "b4476955-095f-4132-eb1d-20d9acb84222"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2462 files belonging to 6 classes.\n",
            "Using 1970 files for training.\n",
            "Found 2462 files belonging to 6 classes.\n",
            "Using 492 files for validation.\n"
          ]
        }
      ]
    }
  ]
}